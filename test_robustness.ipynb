{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LasseS123/Emotional-Claim-Generation-Verification/blob/main/test_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generation"
      ],
      "metadata": {
        "id": "wYNFJ5DhNX_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schritt A: Notwendige Bibliotheken installieren (mit Update f√ºr bitsandbytes)\n",
        "!pip install --upgrade transformers torch bitsandbytes accelerate pandas tqdm\n",
        "\n",
        "# Schritt B: Alle n√∂tigen Module importieren\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "from google.colab import userdata\n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "# 1. Hugging Face Token sicher laden\n",
        "try:\n",
        "    hf_token = userdata.get('HF_Token')\n",
        "    print(\"‚úÖ Hugging Face Token erfolgreich geladen.\")\n",
        "except Exception as e:\n",
        "    print(\"üî¥ FEHLER: Hast du den HF_TOKEN im Secret Manager gespeichert?\")\n",
        "\n",
        "# 2. Modell-ID f√ºr Qwen 7B festlegen\n",
        "MODEL_ID = \"Qwen/Qwen1.5-7B-Chat\"\n",
        "\n",
        "# 3. Konfiguration f√ºr 4-Bit-Quantisierung, um Speicher zu sparen\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# 4. Tokenizer und Modell laden (Dieser Schritt dauert bei 7B weniger lange als bei 72B!)\n",
        "print(f\"Lade Tokenizer f√ºr {MODEL_ID}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=hf_token)\n",
        "\n",
        "print(f\"Lade Modell '{MODEL_ID}'...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=\"auto\", # Weist das Modell automatisch der A100-GPU zu\n",
        "    quantization_config=quantization_config,\n",
        "    token=hf_token\n",
        ")\n",
        "print(f\"‚úÖ {MODEL_ID}-Modell erfolgreich geladen und bereit!\")\n",
        "\n",
        "# 5. Pipeline f√ºr die Textgenerierung erstellen\n",
        "qwen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=250,\n",
        "    model_kwargs={\"temperature\": 0.3}\n",
        ")\n",
        "print(\"‚úÖ Text-Generierungs-Pipeline ist bereit.\")\n",
        "\n",
        "# Anweisungen f√ºr die 6 Emotionen (bleiben gleich)\n",
        "EMOTION_INSTRUCTIONS = {\n",
        "    \"anger\": \"Rewrite the sentence to express strong anger and frustration. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"disgust\": \"Rewrite the sentence to express strong disgust and revulsion. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"fear\": \"Rewrite the sentence to express strong fear, anxiety, and worry. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"happiness\": \"Rewrite the sentence to express strong happiness, joy, and excitement. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"sadness\": \"Rewrite the sentence to express strong sadness, disappointment, and grief. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"surprise\": \"Rewrite the sentence to express strong surprise and astonishment. Preserve all numbers and names. Do not change the factual meaning.\"\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Kernfunktionen (angepasst f√ºr Qwen)\n",
        "# =========================\n",
        "\n",
        "def qwen_colab_transform(base_text: str, instruction: str) -> str:\n",
        "    \"\"\"Sendet eine Anfrage an das lokal geladene Qwen-Modell.\"\"\"\n",
        "    # Spezielles Chat-Format f√ºr Qwen\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a rewriting assistant. Preserve the factual meaning exactly. Output only the rewritten sentence.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}\\n\\nClaim:\\n{base_text}\"},\n",
        "    ]\n",
        "    prompt = qwen_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    try:\n",
        "        outputs = qwen_pipeline(\n",
        "            prompt,\n",
        "            do_sample=True,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id # Unterdr√ºckt eine Warnung\n",
        "        )\n",
        "\n",
        "        # Extrahiere nur den generierten Text\n",
        "        generated_text = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "        return generated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler bei der Inferenz: {e}\")\n",
        "        return base_text # Fallback auf Originaltext\n",
        "\n",
        "# =========================\n",
        "# Hauptskript\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # Passe diesen Dateinamen an, falls deine Input-Datei anders hei√üt\n",
        "    input_filename = \"sample100_gold_pairs.csv\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(input_filename)\n",
        "        print(f\"\\n‚úÖ Eingabedatei '{input_filename}' erfolgreich geladen.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"üî¥ FEHLER: Die Datei '{input_filename}' wurde nicht gefunden. Hast du sie hochgeladen?\")\n",
        "        return\n",
        "\n",
        "    rows = []\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Generiere emotionale Varianten\"):\n",
        "        base = str(row[\"query_text\"]).strip()\n",
        "        qid = row[\"query_id\"]\n",
        "        doc = row[\"doc_id\"]\n",
        "\n",
        "        output_row = {\"query_id\": qid, \"original_query_text\": base, \"doc_id\": doc}\n",
        "\n",
        "        for emotion, instruction in EMOTION_INSTRUCTIONS.items():\n",
        "            # Verwende die neue, f√ºr Qwen angepasste Funktion\n",
        "            rewritten_text = qwen_colab_transform(base, instruction)\n",
        "            output_row[f\"{emotion}_version\"] = rewritten_text\n",
        "\n",
        "        rows.append(output_row)\n",
        "\n",
        "    out = pd.DataFrame(rows)\n",
        "    # Definiere die Spaltenreihenfolge f√ºr eine saubere Ausgabe\n",
        "    column_order = [\n",
        "        \"query_id\", \"original_query_text\", \"doc_id\",\n",
        "        \"anger_version\", \"disgust_version\", \"fear_version\",\n",
        "        \"happiness_version\", \"sadness_version\", \"surprise_version\"\n",
        "    ]\n",
        "    out = out[column_order]\n",
        "\n",
        "    # √Ñndere den Ausgabedateinamen, um das Modell widerzuspiegeln\n",
        "    output_filename = \"emotional_dataset_6_emotions_Qwen7B.csv\"\n",
        "    out.to_csv(output_filename, index=False, encoding=\"utf-8\")\n",
        "    print(f\"\\n‚úÖ Fertig! Die Datei '{output_filename}' wurde erfolgreich erstellt und kann heruntergeladen werden.\")\n",
        "\n",
        "# Skript ausf√ºhren\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hyoxpZrkNhih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhCXhyz4Kr_o"
      },
      "source": [
        "# Robustheits-Analyse f√ºr 6 Emotionen\n",
        "\n",
        "Dieses Notebook testet, wie robust ein Embedding-Modell (`all-MiniLM-L6-v2`) gegen√ºber 6 verschiedenen emotionalen Varianten von Suchanfragen ist. Es vergleicht die Suchergebnisse der Originalanfrage mit denen der emotionalen Varianten und berechnet Metriken wie Recall@20, MRR@20 und die durchschnittliche Rangver√§nderung."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tFmvttnPK981"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRuIwPFVKr_q"
      },
      "outputs": [],
      "source": [
        "# 1. Installation der notwendigen Bibliotheken\n",
        "!pip install sentence-transformers pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHmwuzc1Kr_r"
      },
      "source": [
        "## 2. Konfiguration & Daten laden\n",
        "\n",
        "In diesem Schritt werden alle erforderlichen Daten und das KI-Modell geladen. Bitte stelle sicher, dass die folgenden Dateien in die Colab-Umgebung hochgeladen wurden:\n",
        "- `vclaims_corpus_min.csv`\n",
        "- `emotional_dataset_6_emotions.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIn73b4oKr_r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Lade das Korpus, gegen das gesucht wird\n",
        "try:\n",
        "    corpus_df = pd.read_csv(\"vclaims_corpus_min.csv\")\n",
        "    corpus_df = corpus_df.rename(columns={\"vclaim_id\": \"doc_id\", \"vclaim_text\": \"doc_text\"})\n",
        "    corpus_docs = dict(zip(corpus_df.doc_id, corpus_df.doc_text))\n",
        "    print(f\"‚úÖ Korpus mit {len(corpus_docs)} Dokumenten geladen.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"üî¥ FEHLER: vclaims_corpus_min.csv nicht gefunden. Bitte lade die Datei hoch.\")\n",
        "\n",
        "# Lade das Dataset mit den 6 Emotionen\n",
        "try:\n",
        "    eval_df = pd.read_csv(\"emotional_dataset_6_emotions_Qwen7B.csv\")\n",
        "    print(f\"‚úÖ Emotionales Dataset mit {len(eval_df)} Zeilen geladen.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"üî¥ FEHLER: emotional_dataset_6_emotions.csv nicht gefunden. Bitte lade die Datei hoch.\")\n",
        "\n",
        "\n",
        "# Definiere die zu testenden Emotions-Spalten\n",
        "EMOTION_COLUMNS = [\n",
        "    \"anger_version\",\n",
        "    \"disgust_version\",\n",
        "    \"fear_version\",\n",
        "    \"happiness_version\",\n",
        "    \"sadness_version\",\n",
        "    \"surprise_version\"\n",
        "]\n",
        "\n",
        "# Definiere das Embedding-Modell\n",
        "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "print(f\"\\n‚úÖ Sentence-Transformer-Modell '{MODEL_NAME}' geladen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J16Yt5_Kr_r"
      },
      "source": [
        "## 3. Korpus-Embeddings vorberechnen\n",
        "\n",
        "Um die Auswertung zu beschleunigen, werden die Embeddings f√ºr alle Dokumente im Korpus einmalig im Voraus berechnet und im GPU-Speicher gehalten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaED27-cKr_r"
      },
      "outputs": [],
      "source": [
        "print(\"Erstelle Embeddings f√ºr das Korpus... (kann einen Moment dauern)\")\n",
        "corpus_ids = list(corpus_docs.keys())\n",
        "corpus_embeddings = model.encode(\n",
        "    [corpus_docs[doc_id] for doc_id in corpus_ids],\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "print(\"‚úÖ Korpus-Embeddings sind fertig.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Rwem97Kr_s"
      },
      "source": [
        "## 4. Haupt-Auswertung\n",
        "\n",
        "Jetzt wird die eigentliche Analyse durchgef√ºhrt. Das Skript iteriert durch jede Zeile deines Datasets, erstellt Embeddings f√ºr die Originalanfrage und f√ºr jede der sechs emotionalen Varianten und vergleicht die Suchergebnisse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2b9hbr_Kr_s"
      },
      "outputs": [],
      "source": [
        "def calculate_recall(retrieved_ids, relevant_id, k=20):\n",
        "    return 1 if relevant_id in retrieved_ids[:k] else 0\n",
        "\n",
        "def calculate_mrr(retrieved_ids, relevant_id, k=20):\n",
        "    try:\n",
        "        rank = retrieved_ids[:k].index(relevant_id) + 1\n",
        "        return 1.0 / rank\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_rank_change(base_rank, style_rank):\n",
        "    if base_rank is None or style_rank is None:\n",
        "        return None\n",
        "    return style_rank - base_rank # Positiv = Rang wurde schlechter\n",
        "\n",
        "def get_rank(retrieved_ids, relevant_id):\n",
        "    try:\n",
        "        return retrieved_ids.index(relevant_id) + 1\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "results = []\n",
        "\n",
        "# tqdm sorgt f√ºr einen sch√∂nen Fortschrittsbalken\n",
        "for _, row in tqdm(eval_df.iterrows(), total=len(eval_df), desc=\"Werte Abfragen aus\"):\n",
        "    query_id = row['query_id']\n",
        "    doc_id_gold = row['doc_id']\n",
        "\n",
        "    # --- Embedding f√ºr die Original-Abfrage ---\n",
        "    query_base_text = row['original_query_text']\n",
        "    query_base_emb = model.encode(query_base_text, convert_to_tensor=True)\n",
        "    hits_base = util.semantic_search(query_base_emb, corpus_embeddings, top_k=100)[0]\n",
        "    retrieved_base = [corpus_ids[hit['corpus_id']] for hit in hits_base]\n",
        "    rank_base = get_rank(retrieved_base, doc_id_gold)\n",
        "\n",
        "    # --- Iteriere durch jede Emotions-Spalte ---\n",
        "    for emotion_style in EMOTION_COLUMNS:\n",
        "        query_style_text = row[emotion_style]\n",
        "\n",
        "        # Embedding f√ºr die emotionale Variante\n",
        "        query_style_emb = model.encode(query_style_text, convert_to_tensor=True)\n",
        "        hits_style = util.semantic_search(query_style_emb, corpus_embeddings, top_k=100)[0]\n",
        "        retrieved_style = [corpus_ids[hit['corpus_id']] for hit in hits_style]\n",
        "        rank_style = get_rank(retrieved_style, doc_id_gold)\n",
        "\n",
        "        # Speichere alle Ergebnisse\n",
        "        results.append({\n",
        "            'query_id': query_id,\n",
        "            'style': emotion_style.replace(\"_version\", \"\"), # Mache aus \"anger_version\" -> \"anger\"\n",
        "            'doc_id_gold': doc_id_gold,\n",
        "            'Recall@20_BASE': calculate_recall(retrieved_base, doc_id_gold),\n",
        "            'Recall@20_STYLE': calculate_recall(retrieved_style, doc_id_gold),\n",
        "            'MRR@20_BASE': calculate_mrr(retrieved_base, doc_id_gold),\n",
        "            'MRR@20_STYLE': calculate_mrr(retrieved_style, doc_id_gold),\n",
        "            'Rank_BASE': rank_base,\n",
        "            'Rank_STYLE': rank_style,\n",
        "            'Rank_Change': calculate_rank_change(rank_base, rank_style),\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n‚úÖ Auswertung abgeschlossen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZb8XOqcKr_s"
      },
      "source": [
        "## 5. Ergebnisse zusammenfassen und anzeigen\n",
        "\n",
        "Die finalen Ergebnisse werden aggregiert und in einer √ºbersichtlichen Tabelle dargestellt. Au√üerdem werden die detaillierten und die zusammengefassten Ergebnisse als CSV-Dateien gespeichert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPd_yMEcKr_s"
      },
      "outputs": [],
      "source": [
        "# Berechne die durchschnittlichen Metriken pro Emotion\n",
        "summary_list = []\n",
        "\n",
        "for style in results_df['style'].unique():\n",
        "    style_df = results_df[results_df['style'] == style]\n",
        "\n",
        "    # Filtere nur die Paare, bei denen das Originaldokument gefunden wurde\n",
        "    paired_df = style_df.dropna(subset=['Rank_BASE', 'Rank_STYLE'])\n",
        "\n",
        "    summary_list.append({\n",
        "        'style': style,\n",
        "        'N_total': len(style_df),\n",
        "        'N_paired': len(paired_df),\n",
        "        'Recall@20_BASE': style_df['Recall@20_BASE'].mean(),\n",
        "        'Recall@20_STYLE': style_df['Recall@20_STYLE'].mean(),\n",
        "        'MRR@20_BASE': style_df['MRR@20_BASE'].mean(),\n",
        "        'MRR@20_STYLE': style_df['MRR@20_STYLE'].mean(),\n",
        "        'Avg_Rank_Change': paired_df['Rank_Change'].mean(),\n",
        "        'Std_Rank_Change': paired_df['Rank_Change'].std(),\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_list).sort_values('style').reset_index(drop=True)\n",
        "\n",
        "# Berechne die prozentuale Ver√§nderung\n",
        "summary_df['ŒîRecall(%)'] = (summary_df['Recall@20_STYLE'] - summary_df['Recall@20_BASE']) / summary_df['Recall@20_BASE'] * 100\n",
        "summary_df['ŒîMRR(%)'] = (summary_df['MRR@20_STYLE'] - summary_df['MRR@20_BASE']) / summary_df['MRR@20_BASE'] * 100\n",
        "\n",
        "# Formatiere die Ausgabe f√ºr bessere Lesbarkeit\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "summary_to_display = summary_df[[\n",
        "    'style', 'N_total', 'N_paired',\n",
        "    'Recall@20_STYLE', 'ŒîRecall(%)',\n",
        "    'MRR@20_STYLE', 'ŒîMRR(%)',\n",
        "    'Avg_Rank_Change'\n",
        "]]\n",
        "\n",
        "print(\"--- Zusammenfassung der Robustheits-Analyse ---\")\n",
        "display(summary_to_display)\n",
        "\n",
        "# Speichere die detaillierten und zusammengefassten Ergebnisse\n",
        "results_df.to_csv(\"eval_results_6_emotions_detailed.csv\", index=False)\n",
        "summary_df.to_csv(\"eval_summary_6_emotions.csv\", index=False)\n",
        "print(\"\\nGespeichert: 'eval_results_6_emotions_detailed.csv' und 'eval_summary_6_emotions.csv'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LasseS123/Emotional-Claim-Generation-Verification/blob/main/test_robustness.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data generation"
      ],
      "metadata": {
        "id": "wYNFJ5DhNX_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Schritt A: Notwendige Bibliotheken installieren (mit Update fÃ¼r bitsandbytes)\n",
        "!pip install --upgrade transformers torch bitsandbytes accelerate pandas tqdm\n",
        "\n",
        "# Schritt B: Alle nÃ¶tigen Module importieren\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
        "from google.colab import userdata\n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "# 1. Hugging Face Token sicher laden\n",
        "try:\n",
        "    hf_token = userdata.get('HF_Token')\n",
        "    print(\"âœ… Hugging Face Token erfolgreich geladen.\")\n",
        "except Exception as e:\n",
        "    print(\"ðŸ”´ FEHLER: Hast du den HF_TOKEN im Secret Manager gespeichert?\")\n",
        "\n",
        "# 2. Modell-ID fÃ¼r Qwen 7B festlegen\n",
        "MODEL_ID = \"Qwen/Qwen1.5-7B-Chat\"\n",
        "\n",
        "# 3. Konfiguration fÃ¼r 4-Bit-Quantisierung, um Speicher zu sparen\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# 4. Tokenizer und Modell laden (Dieser Schritt dauert bei 7B weniger lange als bei 72B!)\n",
        "print(f\"Lade Tokenizer fÃ¼r {MODEL_ID}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, token=hf_token)\n",
        "\n",
        "print(f\"Lade Modell '{MODEL_ID}'...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=\"auto\", # Weist das Modell automatisch der A100-GPU zu\n",
        "    quantization_config=quantization_config,\n",
        "    token=hf_token\n",
        ")\n",
        "print(f\"âœ… {MODEL_ID}-Modell erfolgreich geladen und bereit!\")\n",
        "\n",
        "# 5. Pipeline fÃ¼r die Textgenerierung erstellen\n",
        "qwen_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=250,\n",
        "    model_kwargs={\"temperature\": 0.3}\n",
        ")\n",
        "print(\"âœ… Text-Generierungs-Pipeline ist bereit.\")\n",
        "\n",
        "# Anweisungen fÃ¼r die 6 Emotionen (bleiben gleich)\n",
        "EMOTION_INSTRUCTIONS = {\n",
        "    \"anger\": \"Rewrite the sentence to express strong anger and frustration. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"disgust\": \"Rewrite the sentence to express strong disgust and revulsion. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"fear\": \"Rewrite the sentence to express strong fear, anxiety, and worry. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"happiness\": \"Rewrite the sentence to express strong happiness, joy, and excitement. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"sadness\": \"Rewrite the sentence to express strong sadness, disappointment, and grief. Preserve all numbers and names. Do not change the factual meaning.\",\n",
        "    \"surprise\": \"Rewrite the sentence to express strong surprise and astonishment. Preserve all numbers and names. Do not change the factual meaning.\"\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# Kernfunktionen (angepasst fÃ¼r Qwen)\n",
        "# =========================\n",
        "\n",
        "def qwen_colab_transform(base_text: str, instruction: str) -> str:\n",
        "    \"\"\"Sendet eine Anfrage an das lokal geladene Qwen-Modell.\"\"\"\n",
        "    # Spezielles Chat-Format fÃ¼r Qwen\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a rewriting assistant. Preserve the factual meaning exactly. Output only the rewritten sentence.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{instruction}\\n\\nClaim:\\n{base_text}\"},\n",
        "    ]\n",
        "    prompt = qwen_pipeline.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    try:\n",
        "        outputs = qwen_pipeline(\n",
        "            prompt,\n",
        "            do_sample=True,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id # UnterdrÃ¼ckt eine Warnung\n",
        "        )\n",
        "\n",
        "        # Extrahiere nur den generierten Text\n",
        "        generated_text = outputs[0]['generated_text'][len(prompt):].strip()\n",
        "        return generated_text\n",
        "    except Exception as e:\n",
        "        print(f\"Fehler bei der Inferenz: {e}\")\n",
        "        return base_text # Fallback auf Originaltext\n",
        "\n",
        "# =========================\n",
        "# Hauptskript\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # Passe diesen Dateinamen an, falls deine Input-Datei anders heiÃŸt\n",
        "    input_filename = \"sample100_gold_pairs.csv\"\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(input_filename)\n",
        "        print(f\"\\nâœ… Eingabedatei '{input_filename}' erfolgreich geladen.\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ðŸ”´ FEHLER: Die Datei '{input_filename}' wurde nicht gefunden. Hast du sie hochgeladen?\")\n",
        "        return\n",
        "\n",
        "    rows = []\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df), desc=\"Generiere emotionale Varianten\"):\n",
        "        base = str(row[\"query_text\"]).strip()\n",
        "        qid = row[\"query_id\"]\n",
        "        doc = row[\"doc_id\"]\n",
        "\n",
        "        output_row = {\"query_id\": qid, \"original_query_text\": base, \"doc_id\": doc}\n",
        "\n",
        "        for emotion, instruction in EMOTION_INSTRUCTIONS.items():\n",
        "            # Verwende die neue, fÃ¼r Qwen angepasste Funktion\n",
        "            rewritten_text = qwen_colab_transform(base, instruction)\n",
        "            output_row[f\"{emotion}_version\"] = rewritten_text\n",
        "\n",
        "        rows.append(output_row)\n",
        "\n",
        "    out = pd.DataFrame(rows)\n",
        "    # Definiere die Spaltenreihenfolge fÃ¼r eine saubere Ausgabe\n",
        "    column_order = [\n",
        "        \"query_id\", \"original_query_text\", \"doc_id\",\n",
        "        \"anger_version\", \"disgust_version\", \"fear_version\",\n",
        "        \"happiness_version\", \"sadness_version\", \"surprise_version\"\n",
        "    ]\n",
        "    out = out[column_order]\n",
        "\n",
        "    # Ã„ndere den Ausgabedateinamen, um das Modell widerzuspiegeln\n",
        "    output_filename = \"emotional_dataset_6_emotions_Qwen7B.csv\"\n",
        "    out.to_csv(output_filename, index=False, encoding=\"utf-8\")\n",
        "    print(f\"\\nâœ… Fertig! Die Datei '{output_filename}' wurde erfolgreich erstellt und kann heruntergeladen werden.\")\n",
        "\n",
        "# Skript ausfÃ¼hren\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hyoxpZrkNhih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhCXhyz4Kr_o"
      },
      "source": [
        "# Robustheits-Analyse fÃ¼r 6 Emotionen\n",
        "\n",
        "Dieses Notebook testet, wie robust ein Embedding-Modell (`all-MiniLM-L6-v2`) gegenÃ¼ber 6 verschiedenen emotionalen Varianten von Suchanfragen ist. Es vergleicht die Suchergebnisse der Originalanfrage mit denen der emotionalen Varianten und berechnet Metriken wie Recall@20, MRR@20 und die durchschnittliche RangverÃ¤nderung."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tFmvttnPK981"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRuIwPFVKr_q"
      },
      "outputs": [],
      "source": [
        "# 1. Installation der notwendigen Bibliotheken\n",
        "!pip install sentence-transformers pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHmwuzc1Kr_r"
      },
      "source": [
        "## 2. Konfiguration & Daten laden\n",
        "\n",
        "In diesem Schritt werden alle erforderlichen Daten und das KI-Modell geladen. Bitte stelle sicher, dass die folgenden Dateien in die Colab-Umgebung hochgeladen wurden:\n",
        "- `vclaims_corpus_min.csv`\n",
        "- `emotional_dataset_6_emotions.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIn73b4oKr_r"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Lade das Korpus, gegen das gesucht wird\n",
        "try:\n",
        "    corpus_df = pd.read_csv(\"vclaims_corpus_min.csv\")\n",
        "    corpus_df = corpus_df.rename(columns={\"vclaim_id\": \"doc_id\", \"vclaim_text\": \"doc_text\"})\n",
        "    corpus_docs = dict(zip(corpus_df.doc_id, corpus_df.doc_text))\n",
        "    print(f\"âœ… Korpus mit {len(corpus_docs)} Dokumenten geladen.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ðŸ”´ FEHLER: vclaims_corpus_min.csv nicht gefunden. Bitte lade die Datei hoch.\")\n",
        "\n",
        "# Lade das Dataset mit den 6 Emotionen\n",
        "try:\n",
        "    eval_df = pd.read_csv(\"emotional_dataset_6_emotions_Qwen7B.csv\")\n",
        "    print(f\"âœ… Emotionales Dataset mit {len(eval_df)} Zeilen geladen.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"ðŸ”´ FEHLER: emotional_dataset_6_emotions.csv nicht gefunden. Bitte lade die Datei hoch.\")\n",
        "\n",
        "\n",
        "# Definiere die zu testenden Emotions-Spalten\n",
        "EMOTION_COLUMNS = [\n",
        "    \"anger_version\",\n",
        "    \"disgust_version\",\n",
        "    \"fear_version\",\n",
        "    \"happiness_version\",\n",
        "    \"sadness_version\",\n",
        "    \"surprise_version\"\n",
        "]\n",
        "\n",
        "# Definiere das Embedding-Modell\n",
        "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "model = SentenceTransformer(MODEL_NAME)\n",
        "print(f\"\\nâœ… Sentence-Transformer-Modell '{MODEL_NAME}' geladen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J16Yt5_Kr_r"
      },
      "source": [
        "## 3. Korpus-Embeddings vorberechnen\n",
        "\n",
        "Um die Auswertung zu beschleunigen, werden die Embeddings fÃ¼r alle Dokumente im Korpus einmalig im Voraus berechnet und im GPU-Speicher gehalten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaED27-cKr_r"
      },
      "outputs": [],
      "source": [
        "print(\"Erstelle Embeddings fÃ¼r das Korpus... (kann einen Moment dauern)\")\n",
        "corpus_ids = list(corpus_docs.keys())\n",
        "corpus_embeddings = model.encode(\n",
        "    [corpus_docs[doc_id] for doc_id in corpus_ids],\n",
        "    convert_to_tensor=True,\n",
        "    show_progress_bar=True\n",
        ")\n",
        "print(\"âœ… Korpus-Embeddings sind fertig.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Rwem97Kr_s"
      },
      "source": [
        "## 4. Haupt-Auswertung\n",
        "\n",
        "Jetzt wird die eigentliche Analyse durchgefÃ¼hrt. Das Skript iteriert durch jede Zeile deines Datasets, erstellt Embeddings fÃ¼r die Originalanfrage und fÃ¼r jede der sechs emotionalen Varianten und vergleicht die Suchergebnisse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2b9hbr_Kr_s"
      },
      "outputs": [],
      "source": [
        "def calculate_recall(retrieved_ids, relevant_id, k=20):\n",
        "    return 1 if relevant_id in retrieved_ids[:k] else 0\n",
        "\n",
        "def calculate_mrr(retrieved_ids, relevant_id, k=20):\n",
        "    try:\n",
        "        rank = retrieved_ids[:k].index(relevant_id) + 1\n",
        "        return 1.0 / rank\n",
        "    except ValueError:\n",
        "        return 0.0\n",
        "\n",
        "def calculate_rank_change(base_rank, style_rank):\n",
        "    if base_rank is None or style_rank is None:\n",
        "        return None\n",
        "    return style_rank - base_rank # Positiv = Rang wurde schlechter\n",
        "\n",
        "def get_rank(retrieved_ids, relevant_id):\n",
        "    try:\n",
        "        return retrieved_ids.index(relevant_id) + 1\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "results = []\n",
        "\n",
        "# tqdm sorgt fÃ¼r einen schÃ¶nen Fortschrittsbalken\n",
        "for _, row in tqdm(eval_df.iterrows(), total=len(eval_df), desc=\"Werte Abfragen aus\"):\n",
        "    query_id = row['query_id']\n",
        "    doc_id_gold = row['doc_id']\n",
        "\n",
        "    # --- Embedding fÃ¼r die Original-Abfrage ---\n",
        "    query_base_text = row['original_query_text']\n",
        "    query_base_emb = model.encode(query_base_text, convert_to_tensor=True)\n",
        "    hits_base = util.semantic_search(query_base_emb, corpus_embeddings, top_k=100)[0]\n",
        "    retrieved_base = [corpus_ids[hit['corpus_id']] for hit in hits_base]\n",
        "    rank_base = get_rank(retrieved_base, doc_id_gold)\n",
        "\n",
        "    # --- Iteriere durch jede Emotions-Spalte ---\n",
        "    for emotion_style in EMOTION_COLUMNS:\n",
        "        query_style_text = row[emotion_style]\n",
        "\n",
        "        # Embedding fÃ¼r die emotionale Variante\n",
        "        query_style_emb = model.encode(query_style_text, convert_to_tensor=True)\n",
        "        hits_style = util.semantic_search(query_style_emb, corpus_embeddings, top_k=100)[0]\n",
        "        retrieved_style = [corpus_ids[hit['corpus_id']] for hit in hits_style]\n",
        "        rank_style = get_rank(retrieved_style, doc_id_gold)\n",
        "\n",
        "        # Speichere alle Ergebnisse\n",
        "        results.append({\n",
        "            'query_id': query_id,\n",
        "            'style': emotion_style.replace(\"_version\", \"\"), # Mache aus \"anger_version\" -> \"anger\"\n",
        "            'doc_id_gold': doc_id_gold,\n",
        "            'Recall@20_BASE': calculate_recall(retrieved_base, doc_id_gold),\n",
        "            'Recall@20_STYLE': calculate_recall(retrieved_style, doc_id_gold),\n",
        "            'MRR@20_BASE': calculate_mrr(retrieved_base, doc_id_gold),\n",
        "            'MRR@20_STYLE': calculate_mrr(retrieved_style, doc_id_gold),\n",
        "            'Rank_BASE': rank_base,\n",
        "            'Rank_STYLE': rank_style,\n",
        "            'Rank_Change': calculate_rank_change(rank_base, rank_style),\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\nâœ… Auswertung abgeschlossen.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZb8XOqcKr_s"
      },
      "source": [
        "## 5. Ergebnisse zusammenfassen und anzeigen\n",
        "\n",
        "Die finalen Ergebnisse werden aggregiert und in einer Ã¼bersichtlichen Tabelle dargestellt. AuÃŸerdem werden die detaillierten und die zusammengefassten Ergebnisse als CSV-Dateien gespeichert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPd_yMEcKr_s"
      },
      "outputs": [],
      "source": [
        "# Berechne die durchschnittlichen Metriken pro Emotion\n",
        "summary_list = []\n",
        "\n",
        "for style in results_df['style'].unique():\n",
        "    style_df = results_df[results_df['style'] == style]\n",
        "\n",
        "    # Filtere nur die Paare, bei denen das Originaldokument gefunden wurde\n",
        "    paired_df = style_df.dropna(subset=['Rank_BASE', 'Rank_STYLE'])\n",
        "\n",
        "    summary_list.append({\n",
        "        'style': style,\n",
        "        'N_total': len(style_df),\n",
        "        'N_paired': len(paired_df),\n",
        "        'Recall@20_BASE': style_df['Recall@20_BASE'].mean(),\n",
        "        'Recall@20_STYLE': style_df['Recall@20_STYLE'].mean(),\n",
        "        'MRR@20_BASE': style_df['MRR@20_BASE'].mean(),\n",
        "        'MRR@20_STYLE': style_df['MRR@20_STYLE'].mean(),\n",
        "        'Avg_Rank_Change': paired_df['Rank_Change'].mean(),\n",
        "        'Std_Rank_Change': paired_df['Rank_Change'].std(),\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_list).sort_values('style').reset_index(drop=True)\n",
        "\n",
        "# Berechne die prozentuale VerÃ¤nderung\n",
        "summary_df['Î”Recall(%)'] = (summary_df['Recall@20_STYLE'] - summary_df['Recall@20_BASE']) / summary_df['Recall@20_BASE'] * 100\n",
        "summary_df['Î”MRR(%)'] = (summary_df['MRR@20_STYLE'] - summary_df['MRR@20_BASE']) / summary_df['MRR@20_BASE'] * 100\n",
        "\n",
        "# Formatiere die Ausgabe fÃ¼r bessere Lesbarkeit\n",
        "pd.options.display.float_format = '{:,.3f}'.format\n",
        "summary_to_display = summary_df[[\n",
        "    'style', 'N_total', 'N_paired',\n",
        "    'Recall@20_STYLE', 'Î”Recall(%)',\n",
        "    'MRR@20_STYLE', 'Î”MRR(%)',\n",
        "    'Avg_Rank_Change'\n",
        "]]\n",
        "\n",
        "print(\"--- Zusammenfassung der Robustheits-Analyse ---\")\n",
        "display(summary_to_display)\n",
        "\n",
        "# Speichere die detaillierten und zusammengefassten Ergebnisse\n",
        "results_df.to_csv(\"eval_results_6_emotions_detailed.csv\", index=False)\n",
        "summary_df.to_csv(\"eval_summary_6_emotions.csv\", index=False)\n",
        "print(\"\\nGespeichert: 'eval_results_6_emotions_detailed.csv' und 'eval_summary_6_emotions.csv'\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}